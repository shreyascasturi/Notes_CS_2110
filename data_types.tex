\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{amsthm}
\usepackage{array,mathtools}
\newcommand*{\carry}[1][1]{\overset{#1}}
\newcolumntype{B}[1]{r*{#1}{@{\,}r}}
\newtheorem*{remark}
{Remark}
\title{Datatypes -- Chapter 1, For CS 2110}
\author{Shreyas Casturi}
\date{}
\begin{document}
\maketitle

\newpage
\doublespacing
\tableofcontents
\singlespacing

\newpage

\section{Chapter 1: Datatypes}

If we aim to have any sort of discussion about the architectures that underpin computers, we must first
understand \textit{binary} numbers and their importance. Indeed, a base 10 numerical system does not lend itself well to computing.

When I say, "what is five?", you may draw the number five, the word "five", five lines, a mathematical expression that evaluates to five, so on and so forth.
What we notice is that these are simply \textit{ways or schemes} of denoting something.

So, our base-10 numeric system is another \textit{scheme} of denoting quantities that have no real name. After all, numbers exist independently of us.

Might there be an easier way of expressing what we already know?

\subsection{Binary Numbers}

In the early days of computing, much detail was devoted to the electronics and hardware. Scientists realized that circuits
obeyed a simple rule -- either they were on, or they were off. There was no inbetween.

This made it easier to accept the \textit{base 2 numeric system}. Numbers expressed in this system are
known as \textit{binary} numbers. A single element
of a binary number is known as a \textit{binary digit}, or a \textit{bit}. A binary
digit has one of two values: 0, or 1. A binary number
is composed of \textit{only} binary digits.

So, a random binary number might look like this

\[number = 010001010101000100111000010101\]

Given $n$ bits, how many possible binary numbers can I generate?

\begin{remark}
    Given $n$ binary digits, there are $2^n$ possible binary numbers.
\end{remark}

\begin{proof}
    There are 2 numbers possible for each of the $n$ digits. Multiply
    this out to obtain the result. Start with 1 or 2 digits, and work up from there.
\end{proof}


    Of course, these numbers are worthless on their own. If someone told you that there were "0101010101"
    cats stuck in that burning house on the left, you'd probably look at them funny. You might even inhale some smoke
    and leave. Those poor cats are dead.

\subsection{Assignations in Binary}

    For four binary digits, 16 combinations are generated.
    We may naturally try to assign our old numbers (which we'll call integers) to these 16 combinations.
    But how many orderings are possible?

    There are $n!$ orderings possible, and we'd like to create an ordering
    that is easy enough for all of us to follow. Indeed, we could
    just do something like this:

    \newpage

    \begin{center}
        \begin{tabular}{|c|c|}
          \hline
          Integers & Binary numbers \\
          \hline
          0 & 0001 \\
          1 & 1010 \\
          2 & 1101 \\
          $\vdots$ & $\vdots$\\
          \hline
                     
        \end{tabular}
    \end{center}
    This really isn't helpful, is it.

    Well, what happens if we assign 0000 to 0, naturally, and 1111
    to be the largest possible integer that could be generated? For 16 possible
    combinations, obviously the range is from $[0 \rightarrow 15]$, or
    to put it a little more mathematically, $[0 \rightarrow 2^n - 1]$.

    The most interesting part is this: Let us have only two binary digits. There
    are then four possible binary numbers, and four integers
    we could assign. If 00 is 0, then 11 is 3. Let 01 be 1, and let
    10 be 2.

    Then we get this chart:

    \begin{center}
        \begin{tabular}{|c|c|}
          \hline
          Integers & Binary numbers \\
          \hline
          0 & 00 \\
          1 & 01 \\
          2 & 10 \\
          3 & 11 \\         
          \hline
                     
        \end{tabular}
    \end{center}

    Observe the progression of the binary numbers. Each time we add 1 to our integers, digits
    are being flipped, but exactly what digits?

    Let us do this one last time for 3 binary digits. How many binary numbers can we generate?
    And what is the range of the integers for these binary numbers?

    The chart follows.

        \begin{center}
        \begin{tabular}{|c|c|}
          \hline
          Real numbers & Binary numbers \\
          \hline
          0 & 000 \\
          1 & 001 \\
          2 & 010  \\
          3 & 011 \\
          4 & 100 \\
          5 & 101 \\
          6 & 110 \\
          7 & 111 \\
          \hline
                     
        \end{tabular}
    \end{center}

    A relationship is obvious from the numbers generated, but may not be intuitive.
    Here is what we know, so far, about binary numbers:

    \newpage

    \begin{enumerate}
        \item A binary number is formed from binary digits.
        \item Each binary digit can be 0 or 1.
        \item There are $2^n$ binary numbers generated from $n$ digits.
        \item We know that we could assign $2^n$ of our integers
        to the $2^n$ binary numbers we generate from $n$ binary digits.
        \item We know there are certain intuitive ways to begin this ordering.
        \item Let the $n$ binary digits be all 0 to denote 0, and let the $n$ digits be all 1 to denote the largest possible integer.
        \item But... what happens after that?
    \end{enumerate}

    The more general question we might ask ourselves is \textit{how do we actually determine what numbers to assign to what combinations}?

    One way to do this is to view \textit{each} binary digit as a power of 2. Let us do this like so, for four binary digits:

    \begin{center}
        \begin{tabular}{|c|c|c|c|c|c|}
          \hline
          Integers & $2^3 = 8$ & $2^2 = 4$ & $2^1 = 2$ & $2^0 = 1$ & Binary numbers \\
          \hline
          0 & 0 & 0 & 0 & 0 & 0000 \\
          1 & 0 & 0 & 0 & 1 & 0001 \\
          2 & 0 & 0 & 1 & 0 & 0010 \\
          3 & 0 & 0 & 1 & 1 & 0011 \\
          4 & 0 & 1 & 0 & 0 & 0100 \\
          5 & 0 & 1 & 0 & 1 & 0101 \\
          6 & 0 & 1 & 1 & 0 & 0110 \\         
          7 & 0 & 1 & 1 & 1 & 0111 \\
          8 & 1 & 0 & 0 & 0 & 1000 \\
          9 & 1 & 0 & 0 & 1 & 1001 \\
          10 & 1 & 0 & 1 & 0 & 1010 \\
          11 & 1 & 0 & 1 & 1 & 1011 \\
          12 & 1 & 1 & 0 & 0 & 1100 \\
          13 & 1 & 1 & 0 & 1 & 1101 \\
          14 & 1 & 1 & 1 & 0 & 1110 \\
          15 & 1 & 1 & 1 & 1 & 1111 \\
          \hline
        \end{tabular}
    \end{center}

    Then, we can intuitively break down any binary number given to us by writing
    the powers of 2 above these numbers, starting with $2^0$ for the right-most digit,
    and ending with $2^{n - 1}$ for the $n$ digits given to us.

    Notice then that all of these numbers can be written as \textbf{sums of various powers of 2}.

    Let us ask ourselves some questions:

    \begin{enumerate}
        \item Given $n$ binary digits, how many possible binary numbers can be made?
        \item Given $n$ binary digits, what is the largest power of 2 possible, and what digit
        is it found at?
        \item Given $n$ binary digits, how many possible integers can be assigned, and what
        is the range of these integers, assuming only 0 and the positive integers are used?
    \end{enumerate}
    

    \begin{remark} Some Facts On Binary Digits:
            \begin{enumerate}
                \item For $n$ binary digits, $2^n$ binary numbers can be generated.
                \item Following from the chart above, the largest power of 2 possible is
                $2^{n - 1}$. It is found at the left-most digit.
                \item Given that we map integers to binary numbers in a one-to-one correspondence,
                then $2^n$ integers can be assigned. Assuming only 0 and the positive integers are used,
                then the range of integers is $[0 \rightarrow (2^{n} - 1)]$.
            \end{enumerate}
        \end{remark}

        %%But this all begs the question: \textit{what about negative numbers?}

        
Before we do anything else with binary numbers, we should first make sure we are comfortable with
basic operations involving those binary numbers.

\subsection{Addition and Subtraction In Binary}

We should get comfortable thinking in binary terms, so this means we should have some experience
operating with binary numbers -- namely in addition and subtraction. We will use the binary-integer
relationships we have described above to help us figure out what our binary result should be.

We have already discussed that there are only ever 2 values in each bit of a binary number -- 0 or 1, and that
the place values are simply powers of 2, starting from $2^0$, all the way to $2^{n - 1}$.

With this in mind, we shall pose some problems.

\subsubsection{Basic Addition}

\textbf{Problem 1: } Let $A = 0010 \; 1110$, and let $B = 0110 \; 1101$. What is $A + B$? \\

\textbf{Answer: }

We can write the problem as

\begin{equation*}
    \begin{array}{B3}
      0010 &              1110 \\ 
      {}+ 0110 &              1101 \\ \hline
          xxxx & xxxx
    \end{array}
    \end{equation*}

    \begin{enumerate}
        \item (Both Zero Bits): $0 + 0 = 0$
        \item (Bits Not Equal): $0 + 1 = 1 + 0 = 1$.
        \item (Both Bits == 1): $1 + 1 = 0 (\text{carry over 1})$
    \end{enumerate}
    
    The rule for addition is simple -- if both bits are 0, the answer bit is 0. If both of the
    bits are not the same, then it's a 1, with no carry. If both of the bits are 1, then the result
    is a 0, and you carry a 1 over. Basically, 1 + 1 = 0 (with a carry of 1 to the next digit).

    So, our addition problem then becomes

\begin{equation*}
    \begin{array}{B3}

      \carry0 \carry0 1 \carry 0 &              \carry 1 110 \\ 
      {} + 0110 &              1101 \\ \hline
           1001 &                  1011
                                 
    \end{array}
    \end{equation*}

    What is this answer in base 10 format?

    I won't write out the whole tables, but
    you get

    \[1001 \; 1011_2 = 2^7 + 2^4 + 2^3 + 2^1 + 2^0 = 128 + 16 + 8 + 2 + 1 = 155. \]

    If you turn $A$ and $B$ into their base-10 expressions and add those two integers together,
    you should get the same result. If you get stuck, try turning your adding terms into
    their base-10 forms and adding from there. It is a handy reference.

    \subsubsection{Basic Subtraction}
    This will be filled in later.



    Now that we know how to work with binary numbers and perform operations on them,
    we may ask ourselves a simple question -- we've only covered the positive integers. \textit{What about negative
    numbers?}



  \subsection{Beyond The Positive}
  We usually deal with both positive and negative integers, but so far we've only dealt with positive integers
  and zero, strictly. We must find a way to incorporate negative integers.

  Before we do that, we should define some terms.

  Assuming there is a number (binary or otherwise) labeled $x$, the \textbf{additive inverse} of $x$, labeled as $x^{-1}$
  is another number such that $x + x^{-1} = 0$. This means that the additive inverse of $4$ is $-4$, and in binary, this
  means $0100 + 1100 = 0000$; $4 + -4 = 0$.

  Now, we can move onto actual methods of representation.
  
  \subsubsection{Signed Magnitude}
  
  One logical idea is that given a binary number of $n$ bits, reserve one bit -- the leftmost bit,
  or the most significant bit -- to represent the sign
  of the number. This is called the \textit{signed magnitude}.

  So 0000 is 0, 1000 is -0, 0001 is 1, and 1001 is -1, so on and so forth.

  We will make use of a chart from the previous sections and continue to update as such, with
  each scheme we get/invent.

  \textbf{We shall use this chart to show four-bit numbers and our various numbering schemes.}

  The first two are the unsigned integers and signed magnitude. 
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
          \hline
          Binary Numbers & Unsigned Integers & Signed Ints \\
          \hline
          0000 & 0 & 0\\ 
          0001 & 1 & 1\\  
          0010 & 2 & 2\\  
          0011 & 3 & 3\\  
          0100 & 4 & 4\\  
          0101 & 5 & 5\\  
          0110 & 6 & 6\\         
          0111 & 7 & 7\\  
          1000 & 8 & -0\\  
          1001 & 9 & -1\\  
          1010 & 10 & -2\\
          1011 & 11 & -3\\
          1100 & 12 & -4\\
          1101 & 13 & -5\\
          1110 & 14 & -6\\
          1111 & 15 & -7\\
          \hline
        \end{tabular}
    \end{center}

    \subsubsection{Problems with Signed Magnitude}

    While the signed magnitude is intuitive, there are some problems -- namely,
    why are we going to have two zeroes (0000 and 1000)?

    Is there a way to improve upon this signed magnitude scheme?

    There in fact is, but it isn't immediately intuitive. If we start with a
    number line as so

    \textbf{INSERT THE FUCKING NUMBER LINE}

    We'll put 0 and 0000 at the exact middle, and go up by 1 \textbf{until} our
    left-most significant bit becomes 1. At this first instance (1000, to be exact),
    we're going to assign this number $-(2^3)$, or -8. Visually, we'll \textbf{wrap around}
    the number line and start from the back, going back towards 0000. Our final number, 1111,
    will be -1.

    This number scheme is known as \textbf{two's complement}, and it is the major scheme
    that we'll be using throughout this course and, for that matter, all computers.

    Why is this scheme so widely used? % This has to do with something known as \textit{modular arithmetic},
    % and how additions under \textit{modulo $2^n$} with these particular assignations
    % works nicely and obeys the laws of modular arithmetic.
    Notice how the difference between positive and negative
    numbers is nothing more than a \textbf{bitwise inverse} (flip the bits and add 1). Also note that because we can find
    the additive inverse of a number easily, there's no reason to actually perform (or remember)
    \textit{how} to perform subtraction, when all you're doing is still doing the act of addition
    with an additive inverse.

    This allows us to gain another column in our chart:

    \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
          \hline
          Binary Numbers & Unsigned Integers & Signed Ints & 2's Complement \\
          \hline
          0000 & 0 & 0 & 0 \\ 
          0001 & 1 & 1 & 1\\  
          0010 & 2 & 2 & 2\\  
          0011 & 3 & 3 & 3\\  
          0100 & 4 & 4 & 4\\  
          0101 & 5 & 5 & 5\\  
          0110 & 6 & 6 & 6\\         
          0111 & 7 & 7 & 7\\  
          1000 & 8 & -0 & -8 \\  
          1001 & 9 & -1 & -7 \\  
          1010 & 10 & -2 & -6 \\
          1011 & 11 & -3 & -5 \\
          1100 & 12 & -4 & -4 \\
          1101 & 13 & -5 & -3 \\
          1110 & 14 & -6 & -2 \\
          1111 & 15 & -7 & -1 \\
          \hline
        \end{tabular}
    \end{center}

    We immediately gain some questions:

    \begin{enumerate}
        \item Given an $n$-bit binary number, what is the largest positive value we can have,
        and what is the largest negative value we can have, assuming we're working in a 2's complement
        system?
        \item What is always the smallest negative number (-1) represented
        as in 2's complement, for any given $n$-bit number?
    \end{enumerate}

    The above is good food for thought. But now that
    we know about 2's complement, we must ask ourselves how to find the \textit{additive inverses}
    of positive numbers, as we'll need to be able to do subtraction (addition with additive inverses)
    easily.

    \textbf{UNLESS OTHERWISE STATED, WE WILL BE USING 2'S COMPLEMENT FROM NOW ON. BE CAREFUL.}

    \subsubsection{Additive Inverses in 2's Complement}

    The easiest, most surefire way to do find
    2's complement additive inverses (negative numbers) -- that is, a way that is foolproof and can never fail,
    is as follows:

    \begin{remark}
        Naive Inversion: Given a number $x$ in 2's complement, in order to find the additive inverse
        of this number, given as $x^{-1}$, simply flip the bits of $x$ and add 1 to the least significant bit.
    \end{remark}


    Of course, for long numbers, this may be a bit of a pain to do. There is an easier way, though it is sometimes
    harder to remember -- I myself have to always do a bit of work to remember/rederive the rule.

    \begin{remark}
        Bossut's Rule: Given a number $x$ in 2's complement, in order to find the additive inverse of this number,
        start from the least-significant bit and go left. Find the \textbf{first} bit that is 1. Then, \textbf{flip}
        all the bits \textbf{to the left} of this first 1 bit. The result will be the additive inverse of $x$, given
        as $x^{-1}$.        
    \end{remark}

    Either way works.

    
        
    \subsection{Overflow}

    In computing, we have often seen errors involving "not-a-number", or integer overflow, or some other
    weird problem -- for example, if adding \texttt{ints} in Java, you may find that very very large ints
    being added together will cause... unexpected results. This is due to a concept known as \textit{overflow},
    where a computer (or particular datatype) simply doesn't have enough bits to represent all pertinent information.

    When dealing with binary numbers, we must obviously consider this problem of overflow.

    \textit{What generates overflow?}

    In order to handle overflow, we must first check the carry-in and carry-out of
    the leading bit, or rather, the most-significant bit.

    When we add or subtract (add with additive inverse) two binary numbers, we
    have overflow if either of these two conditions are satisified:

    \begin{enumerate}
        \item We get a carry into the signed bit/most-significant bit but no carry out.
        \item We get a carry out of the signed bit/most-significant bit but no carry in.
    \end{enumerate}

    Numbers that either have no carry-in and carry-out \textit{or} carry-in and carry-out with
    regards to their most-significant bits are not considered \textit{overflowing}.

    Let us look at some examples of overflow and no overflow.

    \subsubsection{Overflow in Addition And Subtraction}

    \textbf{Problem 1: } Let us take $A = -5, B = -3$. Does the result of $A + B$ overflow?

    We may write our addition out as such

    

    \begin{equation*}
        \begin{array}{B3}
          1110 \\ 
          {}+               1101 \\ \hline
          xxxx
        \end{array}
    \end{equation*}

    We can use our rules of binary addition to observe that

    \begin{equation*}
        \begin{array}{B3}

          \carry 1 110 \\ 
          {} + 1101 \\ \hline
          11011
          
        \end{array}
    \end{equation*}

    There is a carry-into the most significant bit, and the extra 1 at the bottom
    is the carry-out. Hence, this sum \textbf{doesn't} overflow. \\

 \textbf{Problem 2: } Let $A = 4, B = 5$. Does $A + B$ overflow?

    We write our addition as such:

\begin{equation*}
    \begin{array}{B3}
                    0100 \\ 
      {}+           0101 \\ \hline
         xxxx
    \end{array}
    \end{equation*}
    
    Then, our answer is

\begin{equation*}
        \begin{array}{B3}

           \carry 0 100 \\ 
          {} + 0101 \\ \hline
          1001
        \end{array}
    \end{equation*}

    Note that the most significant bit has a 1 carried-into it, but nothing
    carried out of it, because $1 + 0 + 0 = 1$. Hence, this sum will overflow.

    
    \subsection{Sign Extension}

    Let us assume we have a four-bit binary number and eight-bit binary number
    that we have to add together, but we have an adder (a special device that operates
    on bits) that can only add two eight-bit binary numbers.

    We need a way to turn the four-bit binary number into an eight-bit binary number \textit{without} changing
    the number itself.

    One way we can do this is to \textit{extend} the amount of bits that a number has. The way to do this
    is to add some amount of bits to the left of the binary number, based on the \textit{signed} bit of the
    number. So, if a number is negative, the signed bit is 1, and we'll add some amount of 1's to the left
    of the number.

    To answer our original question, we'd take the sign of the four-bit binary number and add another
    four bits based on the sign, so we'd then have two eight-bit binary numbers that we could add
    with our adder.

    \subsubsection{An Example of Addition with Sign Extension}

    \textbf{Problem: } Let $A = 15, B = -63$. Find $C = A + B$.

    $A$ can be written as

    \[A = 01111\]

    and $B$ can of course be written as

    \[B = 1000001\]

    So the addition will be

\begin{equation*}
    \begin{array}{B3}
      01111 \\ 
      {}+          1000001 \\ \hline
         
    \end{array}
    \end{equation*}
    


    We can sign-extend $A$ to have the same amount of bits as $B$ by adding zeroes
    to the left of the most-significant bit. If $A$ were negative, we would add ones to the
    left of the most significant bit.

\begin{equation*}
    \begin{array}{B3}
      0001111 \\ 
      {}+           1000001 \\ \hline
         
    \end{array}
\end{equation*}


The actual addition is

\begin{equation*}
    \begin{array}{B3}
      0001111 \\ 
      {}+           1000001 \\ \hline
      1010000
         
    \end{array}
\end{equation*}

This is of course -48 -- I didn't show the carries because that's kind of a pain to do.
    

    \subsection{Fractional Binary Numbers}

    We may sometimes want to get a decimal number -- an integer with some decimal component
    added to it, like 10.25.

    What we can do is have a regular binary number with a decimal point affixed
    to the right of the \textit{least significant bit}. Here
    is the layout of such a number, with positive powers of 2 to the left of the decimal
    point, and powers of 2 less than 1 to the right
    of the decimal point, like so

    \[[2^3 \mid 2^2 \mid 2^1 \mid 2^0 \mid . \mid 2^{-1} \mid 2^{-2} \mid 2^{-3} \mid \dots]\]

    

    

    
        
\end{document}

